{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "055756bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up imports and libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.feature_extraction.text import  TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import string\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "import nltk\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33dba976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the review data set\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "yelp_reviews = []\n",
    "r_dtypes = {\"stars\": np.float16, \n",
    "            \"useful\": np.int32, \n",
    "            \"funny\": np.int32,\n",
    "            \"cool\": np.int32,\n",
    "           }\n",
    "with open(\"yelp_academic_dataset_review.json\", \"r\", encoding='utf8') as f:\n",
    "    reader = pd.read_json(f, orient=\"records\", lines=True, \n",
    "                          dtype=r_dtypes, chunksize=1000)\n",
    "        \n",
    "    for chunk in reader:\n",
    "        reduced_chunk = chunk.drop(columns=['review_id', 'user_id'])\\\n",
    "                             .query(\"`date` >= '2022-01-01'\")\n",
    "        yelp_reviews.append(reduced_chunk)\n",
    "    \n",
    "yelp_reviews = pd.concat(yelp_reviews, ignore_index=True)\n",
    "#yelp_reviews.describe #80k rows for 12/1/21; 31665  for 2022-01-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "123ef363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import business dataset\n",
    "import pandas as pd\n",
    "yelp_busn = []\n",
    "r_dtypes = {\"stars\": np.float16, \n",
    "            \"latitude\": np.int32, \n",
    "            \"longitude\": np.int32,\n",
    "           }\n",
    "with open(\"yelp_academic_dataset_business.json\", \"r\", encoding='utf8') as f:\n",
    "    reader = pd.read_json(f, orient=\"records\", lines=True, \n",
    "                          dtype=r_dtypes, chunksize=1000)\n",
    "        \n",
    "    for chunk in reader:\n",
    "        reduced_chunk = chunk.drop(columns=['is_open', 'longitude','latitude','hours'])\\\n",
    "                             .query(\"`city` >= 'philadelphia'\")\n",
    "        yelp_busn.append(reduced_chunk)\n",
    "    \n",
    "yelp_busn = pd.concat(yelp_busn, ignore_index=True)\n",
    "#yelp_busn.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b211b590",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'dataframe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17404/1519695830.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#MexicanBusinesses = yelp_busn[yelp_busn['categories'].isIn(['Mexican'])]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mFL_busn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myelp_busn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0myelp_busn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'state'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'FL'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFL_busn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'business_id'\u001b[0m\u001b[1;33m]\u001b[0m                      \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_SparseArray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"module 'pandas' has no attribute '{name}'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'dataframe'"
     ]
    }
   ],
   "source": [
    "yelp_busn\n",
    "#MexicanBusinesses = yelp_busn[yelp_busn['categories'].isIn(['Mexican'])]\n",
    "FL_busn = yelp_busn[yelp_busn['state'].isin(['FL'])]\n",
    "pd.dataframe(FL_busn['business_id']                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "887538a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>text length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drTZrkbpSoJgwKETlFbc3w</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I bought a Fender 1966 Telecaster that the sal...</td>\n",
       "      <td>2022-01-01 15:47:07</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jyxHti29yWdYR00Itt1A2w</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This is our go to for take out when I visit my...</td>\n",
       "      <td>2022-01-02 03:49:01</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jo4ei-c-5H53IxZxAVf1jQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Danielle did a great job!  She listened and cu...</td>\n",
       "      <td>2022-01-03 03:17:03</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YT5CjacTllBtvMaMJS3IbA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>We saw a lot of roaches in the bathroom when w...</td>\n",
       "      <td>2022-01-05 15:55:59</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9MHe5jAym2d8VhT_NbCRyw</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>We  Ordered pork fried rice and beef chow mei ...</td>\n",
       "      <td>2022-01-06 03:59:21</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  stars  useful  funny  cool  \\\n",
       "0  drTZrkbpSoJgwKETlFbc3w    1.0       0      0     0   \n",
       "1  jyxHti29yWdYR00Itt1A2w    5.0       0      0     0   \n",
       "2  Jo4ei-c-5H53IxZxAVf1jQ    5.0       0      0     0   \n",
       "3  YT5CjacTllBtvMaMJS3IbA    1.0       0      0     0   \n",
       "4  9MHe5jAym2d8VhT_NbCRyw    2.0       0      0     0   \n",
       "\n",
       "                                                text                date  \\\n",
       "0  I bought a Fender 1966 Telecaster that the sal... 2022-01-01 15:47:07   \n",
       "1  This is our go to for take out when I visit my... 2022-01-02 03:49:01   \n",
       "2  Danielle did a great job!  She listened and cu... 2022-01-03 03:17:03   \n",
       "3  We saw a lot of roaches in the bathroom when w... 2022-01-05 15:55:59   \n",
       "4  We  Ordered pork fried rice and beef chow mei ... 2022-01-06 03:59:21   \n",
       "\n",
       "   text length  \n",
       "0          641  \n",
       "1          208  \n",
       "2          278  \n",
       "3          514  \n",
       "4          148  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# append text length of review\n",
    "yelp_reviews.describe\n",
    "yelp_reviews['text length'] = yelp_reviews['text'].apply(len)\n",
    "yelp_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3843cf02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars\n",
       "0    1.0\n",
       "1    5.0\n",
       "2    5.0\n",
       "3    1.0\n",
       "4    2.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Pre Processing\n",
    "# 1. Remove Stop Words\n",
    "# 2. Stem\n",
    "# 3. Tokenize\n",
    "# 4. Counts\n",
    "# 5. Replace smileies\n",
    "\n",
    "#does not filter to restaurants - need business dataset\n",
    "#createa dataset without 3 stars since those are neutral\n",
    "yelp_data = yelp_reviews[(yelp_reviews['stars'] > 3) | (yelp_reviews['stars'] < 3)]\n",
    "#yelp_reviews['label'] = 0\n",
    "\n",
    "X = pd.DataFrame(yelp_data['text'])\n",
    "y = pd.DataFrame(yelp_data['stars'])\n",
    "\n",
    "Xhead = X.head()\n",
    "Xhead\n",
    "Yhead = y.head()\n",
    "Yhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8e0e0d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcdc9\\AppData\\Local\\Temp/ipykernel_17404/3065777248.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Xhead['text'] = Xhead['text'].apply(process_text)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[bought, Fender, 1966, Telecaster, salesperson...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[go, take, visit, son, restaurant, desert, hom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Danielle, great, job, listened, cut, hair, wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[saw, lot, roaches, bathroom, woke, us, also, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Ordered, pork, fried, rice, beef, chow, mei, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  [bought, Fender, 1966, Telecaster, salesperson...\n",
       "1  [go, take, visit, son, restaurant, desert, hom...\n",
       "2  [Danielle, great, job, listened, cut, hair, wa...\n",
       "3  [saw, lot, roaches, bathroom, woke, us, also, ...\n",
       "4  [Ordered, pork, fried, rice, beef, chow, mei, ..."
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 Remove stop words - Done\n",
    "def process_text(text):\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "\n",
    "X\n",
    "Xhead['text'] = Xhead['text'].apply(process_text)\n",
    "Xhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c91d537f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17404/938485561.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4356\u001b[0m         \"\"\"\n\u001b[1;32m-> 4357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 \u001b[1;31m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m                 \u001b[1;31m# \"Callable[[Any], Any]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m                 mapped = lib.map_infer(\n\u001b[0m\u001b[0;32m   1099\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17404/938485561.py\u001b[0m in \u001b[0;36mprocess_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mnopunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mchar\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mchar\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mnopunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnopunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnopunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17404/938485561.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mnopunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mchar\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mchar\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mnopunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnopunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnopunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py\u001b[0m in \u001b[0;36mwords\u001b[1;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[0;32m     19\u001b[0m         return [\n\u001b[0;32m     20\u001b[0m             \u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mline_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mignore_lines_startswith\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         ]\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\api.py\u001b[0m in \u001b[0;36mraw\u001b[1;34m(self, fileids)\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[0mcontents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m                 \u001b[0mcontents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\api.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \"\"\"\n\u001b[0;32m    229\u001b[0m         \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_root\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, fileid)\u001b[0m\n\u001b[0;32m    332\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[0m_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mFileSystemPathPointer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\compat.py\u001b[0m in \u001b[0;36m_decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_py3_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0minit_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_decorator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, _path)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[0m_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No such file or directory: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\genericpath.py\u001b[0m in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;34m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#1 Remove stop words - for X instead of test set (takes long time)\n",
    "def process_text(text):\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "\n",
    "X\n",
    "X['text'] = X['text'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f273f797",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcdc9\\AppData\\Local\\Temp/ipykernel_17404/4210125179.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Xhead['stemmed'] = Xhead['text'].apply(lambda x: [snowBallStemmer.stem(y) for y in x]) # Stem every word.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[bought, fender, 1966, telecast, salesperson, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[go, take, visit, son, restaur, desert, home, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[daniell, great, job, listen, cut, hair, way, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[saw, lot, roach, bathroom, woke, us, also, se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[order, pork, fri, rice, beef, chow, mei, fun,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             stemmed\n",
       "0  [bought, fender, 1966, telecast, salesperson, ...\n",
       "1  [go, take, visit, son, restaur, desert, home, ...\n",
       "2  [daniell, great, job, listen, cut, hair, way, ...\n",
       "3  [saw, lot, roach, bathroom, woke, us, also, se...\n",
       "4  [order, pork, fri, rice, beef, chow, mei, fun,..."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 Stem - Done\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "snowBallStemmer = SnowballStemmer(\"english\")\n",
    "Xhead['stemmed'] = Xhead['text'].apply(lambda x: [snowBallStemmer.stem(y) for y in x]) # Stem every word.\n",
    "Xhead = Xhead.drop(columns=['text']) # Get rid of the unstemmed column.\n",
    "Xhead # Print dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b17c3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Stem - - for X instead of test set (takes long time)\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "snowBallStemmer = SnowballStemmer(\"english\")\n",
    "X['stemmed'] = X['text'].apply(lambda x: [snowBallStemmer.stem(y) for y in x]) # Stem every word.\n",
    "X = X.drop(columns=['text']) # Get rid of the unstemmed column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "afe1c2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Tokenize data to turn words into integers for modeling\n",
    "cv = CountVectorizer() #stop_words=my_stop_words, ngram_range=(2,2\n",
    "Xhead['stemmed']=[\" \".join(review) for review in Xhead['stemmed'].values] #convert from list to text\n",
    "Xhead_cv = cv.fit_transform(Xhead['stemmed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3f8ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Tokenize data to turn words into integers for modeling\n",
    "cv = CountVectorizer() #stop_words=my_stop_words, ngram_range=(2,2\n",
    "Xhead['stemmed']=[\" \".join(review) for review in Xhead['stemmed'].values] #convert from list to text\n",
    "Xhead_cv = cv.fit_transform(Xhead['stemmed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0c20ea48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x140 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 150 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xhead_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2202087d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bigram_df = pd.DataFrame(Xhead_cv.toarray(), columns=cv.get_feature_names_out())\n",
    "bigram_frequency = pd.DataFrame(bigram_df.sum(axis=0)).reset_index()\n",
    "bigram_frequency.columns = ['bigram', 'frequency']\n",
    "bigram_frequency = bigram_frequency.sort_values(by='frequency', ascending=False).head(10)\n",
    "plt.bar(bigram_frequency['bigram'],bigram_frequency['frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "21bd468e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (5, 140)\n",
      "Amount of Non-Zero occurrences:  150\n",
      "Density: 21.428571428571427\n"
     ]
    }
   ],
   "source": [
    "Xhead_cv\n",
    "print('Shape of Sparse Matrix: ', Xhead_cv.shape)\n",
    "print('Amount of Non-Zero occurrences: ', Xhead_cv.nnz)\n",
    "# Percentage of non-zero values\n",
    "density = (100.0 * Xhead_cv.nnz / (Xhead_cv.shape[0] * Xhead_cv.shape[1]))\n",
    "print(\"Density: {}\".format((density)))\n",
    "\n",
    "#graphics\n",
    "#wordcloud failed\n",
    "#reviews over time\n",
    "#dist of star ratings\n",
    "#length fo text for ratings\n",
    "#avg monthly rtating\n",
    "#Xhead('text'.most_common(20),columns=['Word', 'Frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "579edd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 0]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00       1.0\n",
      "         2.0       0.00      0.00      0.00       1.0\n",
      "         5.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00       2.0\n",
      "   macro avg       0.00      0.00      0.00       2.0\n",
      "weighted avg       0.00      0.00      0.00       2.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcdc9\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\mcdc9\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mcdc9\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mcdc9\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mcdc9\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mcdc9\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mcdc9\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# set up nb model and run predictions\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xhead_cv, Yhead,test_size=0.3,random_state=101)\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train,y_train)\n",
    "\n",
    "predictions = nb.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf79cf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('vader_lexicon')\n",
    "# Load SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "# Instantiate new SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "# Generate sentiment scores\n",
    "sentiment_scores = Xhead['stemmed'].apply(sid.polarity_scores)\n",
    "sentiment = sentiment_scores.apply(lambda x: x['compound']) #get compound score\n",
    "sentiment\n",
    "#could graph over time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
